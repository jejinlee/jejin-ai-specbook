import streamlit as st
st.set_page_config(page_title="ì‹œë°©ì„œ AI ê²€ìƒ‰ ì‹œìŠ¤í…œ", layout="centered")

from sentence_transformers import SentenceTransformer, util
import torch

# ì •ì œëœ í•­ëª©ë³„ ì‹œë°©ì„œ ë°ì´í„° (ì˜ˆì‹œ)
paragraphs = [
    "ê²½ëŸ‰ ì²œì¥ ê³µì‚¬ëŠ” ì£¼ë¡œ ê²½ëŸ‰ ì² ê³¨(ë°”íƒ•í‹€)ì„ ì´ìš©í•œ ì²œì¥ ë§ˆê°ê³µì‚¬ë¡œ, ë°˜ìí‹€ì€ ì¼ë°˜ì ìœ¼ë¡œ 1000mm ê°„ê²©, ì¸ì„œíŠ¸(ì•µì»¤)ëŠ” 900~1200mm ê°„ê²©ìœ¼ë¡œ ì‹œê³µí•œë‹¤. í‹€ì€ ìˆ˜í‰ì„ ìœ ì§€í•´ì•¼ í•˜ë©°, ì „ê¸°ì„¤ë¹„ë‚˜ í™˜ê¸° ë•íŠ¸ì™€ ê°„ì„­ì´ ì—†ë„ë¡ í•œë‹¤. ì„ê³ ë³´ë“œ ë§ˆê° ì‹œ, ì´ìŒë¶€ëŠ” í¼í‹° ë“±ìœ¼ë¡œ í‰í™œ ì²˜ë¦¬ í›„ ë„ì¥ ë§ˆê°í•œë‹¤.",
    "ì„ê³ ë³´ë“œ ì‹œê³µì€ ê·œê²©ì— ë”°ë¼ ì ì ˆí•œ ê°„ê²©ìœ¼ë¡œ ë‚˜ì‚¬ëª»ì„ ì²´ê²°í•˜ë©°, ì´ìŒë¶€ì—ëŠ” ì¡°ì¸íŠ¸ í…Œì´í”„ì™€ í¼í‹°ë¥¼ ì ìš©í•˜ì—¬ ë§¤ë„ëŸ¬ìš´ í‘œë©´ì„ í™•ë³´í•œë‹¤. ë³´ë“œ ë§ˆê° í›„ì—ëŠ” ë„ì¥ ë˜ëŠ” ë„ë°° ë§ˆê°ì´ ì¼ë°˜ì ì´ë‹¤.",
    "ê²½ëŸ‰ ì¹¸ë§‰ì´ ê³µì‚¬ëŠ” ìŠ¤í„°ë“œ ë° íŠ¸ë™ êµ¬ì¡°ë¡œ ì´ë£¨ì–´ì§€ë©°, ìˆ˜ì§ì¬ ê°„ê²©ì€ 600mm ì´í•˜ë¡œ í•œë‹¤. ë°°ì„ Â·ë°°ê´€ ì‹œ ê³ ë ¤ ì‚¬í•­ì„ ë°˜ì˜í•˜ê³ , ë°©í™” ì„±ëŠ¥ í™•ë³´ë¥¼ ìœ„í•´ ë§ˆê°ì¬ì™€ ì¶©ì§„ì¬ ì‚¬ìš© ê¸°ì¤€ì„ ë”°ë¥¸ë‹¤."
]

@st.cache_resource
def load_embeddings():
    model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')
    embeddings = model.encode(paragraphs, convert_to_tensor=True)
    return model, embeddings, paragraphs

model, corpus_embeddings, paragraphs = load_embeddings()

st.title("ğŸ“˜ ì¸í…Œë¦¬ì–´ ì‹œë°©ì„œ AI ê²€ìƒ‰")

query = st.text_input("ì‹œë°©ì„œ ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ê²½ëŸ‰ ì²œì¥ ë°˜ìí‹€ ê°„ê²©ì€?")

if query:
    query_embedding = model.encode(query, convert_to_tensor=True)
    top_k = min(3, len(paragraphs))
    hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=top_k)

    st.subheader("ğŸ” AI ì‘ë‹µ")
    top_result = paragraphs[hits[0][0]['corpus_id']]
    st.write(top_result)

    with st.expander("ğŸ“„ ê´€ë ¨ ì‹œë°©ì„œ ë¬¸ë‹¨"):
        for hit in hits[0]:
            st.markdown(f"- {paragraphs[hit['corpus_id']]}")
